{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>This notebook was created by Franck Iutzeler, Jerome Malick and Yann Vernaz (2016).</i></small>\n",
    "<!-- Credit (images) Jeffrey Keating Thompson. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"UGA.png\" width=\"30%\" height=\"30%\"></center>\n",
    "<center><h3>Master of Science in Industrial and Applied Mathematics (MSIAM)</h3></center>\n",
    "<hr>\n",
    "<center><h1>Convex and distributed optimization</h1></center>\n",
    "<center><h2>Part II - Classification (3h + 3h home work)</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "In this Lab, we will investigate some gradient-based and proximal algorithms on the binary classification problems with logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Classification and Logistic Regression\n",
    "\n",
    "### Machine Learning as an Optimization problem\n",
    "\n",
    "We have some *data*  $\\mathcal{D}$ consisting of $m$ *examples* $\\{d_i\\}$; each example consisting of a *feature* vector $a_i\\in\\mathbb{R}^d$ and an *observation* $b_i\\in \\mathcal{O}$: $\\mathcal{D} = \\{[a_i,b_i]\\}_{i=1..m}$ .\n",
    "\n",
    "\n",
    "The goal of *supervised learning* is to construct a predictor for the observations when given feature vectors.\n",
    "\n",
    "\n",
    "A popular approach is based on *linear models* which are based on finding a *parameter* $x$ such that the real number $\\langle a_i , x \\rangle$ is used to predict the value of the observation through a *predictor function* $g:\\mathbb{R}\\to \\mathcal{O}$: $g(\\langle a_i , x \\rangle)$ is the predicted value from $a_i$.\n",
    "\n",
    "\n",
    "In order to find such a parameter, we use the available data and a *loss* $\\ell$ that penalizes the error made between the predicted $g(\\langle a_i , x \\rangle)$ and observed $b_i$ values. For each example $i$, the corresponding error function for a parameter $x$ is $f_i(x) =   \\ell( g(\\langle a_i , x \\rangle) ; b_i )$. Using the whole data, the parameter that minimizes the total error is the solution of the minimization problem\n",
    "$$ \\min_{x\\in\\mathbb{R}^d} \\frac{1}{m} \\sum_{i=1}^m f_i(x) = \\frac{1}{m} \\sum_{i=1}^m  \\ell( g(\\langle a_i , x \\rangle) ; b_i ). $$\n",
    "\n",
    "\n",
    "### Binary Classification with Logisitic Regression\n",
    "\n",
    "In our setup, the observations are binary: $\\mathcal{O} = \\{-1 , +1 \\}$, and the *Logistic loss* is used to form the following optimization problem\n",
    "\\begin{align*}\n",
    "\\min_{x\\in\\mathbb{R}^d } f(x) := \\frac{1}{m}  \\sum_{i=1}^m  \\log( 1+\\exp(-b_i \\langle a_i,x \\rangle) ).\n",
    "\\end{align*}\n",
    "\n",
    "Under some statistical hypotheses, $x^\\star = \\arg\\min f(x)$ maximizes the likelihood of the labels knowing the features vector. Then, for a new point $d$ with features vector $a$, \n",
    "$$ p_1(a) = \\mathbb{P}[d\\in \\text{ class }  +1] = \\frac{1}{1+\\exp(-\\langle a;x^\\star \\rangle)} $$\n",
    "Thus, from $a$, if $p_1(a)$ is close to $1$, one can decide that $d$ belongs to class $1$; and the opposite decision if $p(a)$ is close to $0$. Between the two, the appreciation is left to the data scientist depending on the application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised classification datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset\n",
    "\n",
    "We will use LibSVM formatted data, meaning that each line of the file (i.e. each example) will have the form\n",
    "\n",
    "<tt>class feature_number1:feature_value1 feature_number2:feature_value2 ... feature_number$n_i$:feature_value$n_i$ </tt>\n",
    "\n",
    "You may read such a file using MLUtils's <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.util.MLUtils.loadLibSVMFile\">`loadLibSVMFile`</a> routine on the supervised classification datasets below.\n",
    "\n",
    "The elements of the produced RDD have the form of <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LabeledPoint\">`LabeledPoints`</a> composed of a label `example.label` corresponding to the class (+1 or -1) and a feature vector `example.features` generally encoded as a <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.linalg.SparseVector\">`SparseVector`</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up spark environment (using Spark local mode set to # cores on your machine)\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.setMaster(\"local[*]\")\n",
    "conf.setAppName(\"MSIAM part II - Logistic Regression\")\n",
    "\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remind you that you can access this interface (Spark UI) by simply opening http://localhost:4040 in a web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to LibSVM Datasets\n",
    "LibSVMHomeDir=\"data/LibSVM/\"\n",
    "LibName=\"ionosphere.txt\"             # a small dataset to begin with\n",
    "#LibName=\"rcv1_train.binary\"          # a bigger one "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 1__\n",
    "> Form an RDD from the selected dataset.\n",
    "\n",
    "> Count the number of examples, features, the number of examples of class '+1' and the density of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples:  351\n",
      "The number of features is :  34\n",
      "The number of examples of class +1 is :  225\n",
      "Density : 0.884112619406737\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.stat import KernelDensity\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.stat import Statistics\n",
    "import os.path\n",
    "\n",
    "path = os.path.join(LibSVMHomeDir,LibName)\n",
    "data = MLUtils.loadLibSVMFile(sc,path)\n",
    "\n",
    "def nbExamples(rdd) :\n",
    "    return rdd.count()\n",
    "def nbFeatures(rdd) :\n",
    "    nbFeatures = rdd.map(lambda line : line.features.size).sum()\n",
    "    return int(nbFeatures/rdd.count())\n",
    "def density(rdd) :\n",
    "    nbFeatures = rdd.map(lambda line : line.features.size).sum()\n",
    "    nonZeros = data.map(lambda line: line.features.numNonzeros()).sum()\n",
    "    return nonZeros/nbFeatures\n",
    "\n",
    "print(\"Number of examples: \",nbExamples(data))\n",
    "print(\"The number of features is : \",nbFeatures(data))\n",
    "nbClassPlus1Examples = data.map(lambda line: line.label).filter(lambda s : float(s) == 1)\n",
    "print(\"The number of examples of class +1 is : \",nbExamples(nbClassPlus1Examples))\n",
    "print(\"Density :\",density(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "An important first step for learning by regression is to preprocess the dataset. This processing usually consists in:\n",
    "* Adding an intercept, that is an additional feature equal to one for all examples (statistically, this accounts for the fact that the two classes may be imbalanced).\n",
    "* For the dense datasets:\n",
    "    *  normalize to have zero-mean and unit variance for every feature (except the interecept for instance.\n",
    "* For sparse datasets:\n",
    "    * normalize so that the feature vector has unit $\\ell_2$ norm for each example.\n",
    "\n",
    "This does not really change the problem but it will ease the convergence of the applied optimization algorithms.\n",
    "\n",
    "__Question 2__\n",
    "> Form a new RDD with the scaled version of the dataset.\n",
    "\n",
    "> Check that the number of examples, features, and the density is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in the dataset : 351 \n",
      "Number of examples in normalized data : 351\n",
      "\n",
      "Number of features in the dataset : 34 \n",
      "Number of features in normalized data : 35\n",
      "\n",
      "Density of the dataset : 0.884112619406737 \n",
      "Density of the normalized dataset : 0.8588522588522588\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.feature import Normalizer\n",
    "from pyspark.mllib.util import *\n",
    "\n",
    "#def addInterceptToLine(line) :\n",
    "#    return LabeledPoint(line.label,SparseVector(line.features.size+1,np.append(line.features.indices,34),np.append(line.features.values,1)))\n",
    "\n",
    "normalizedData = data.map(lambda line : LabeledPoint(line.label,Normalizer().transform(line.features.toArray())))\n",
    "scaledNormData = normalizedData.map(lambda line : LabeledPoint(line.label,np.append(line.features.toArray(),1)))\n",
    "\n",
    "print(\"Number of examples in the dataset :\",nbExamples(data),\"\\n\\\n",
    "Number of examples in normalized data :\",nbExamples(scaledNormData))\n",
    "\n",
    "print(\"\\nNumber of features in the dataset :\",nbFeatures(data),\"\\n\\\n",
    "Number of features in normalized data :\",nbFeatures(scaledNormData))\n",
    "\n",
    "print(\"\\nDensity of the dataset :\",density(data),\"\\n\\\n",
    "Density of the normalized dataset :\",density(scaledNormData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Initialization\n",
    "\n",
    "We will set up here the variables, and the training versus testing dataset. Indeed, we will take a portion of the dataset to learn called the `learning set`, say $95$%, and we will test our predictions on the rest, the `testing set`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3__\n",
    "\n",
    ">  Split the scaled dataset into a training and a testing set. For instance, you may use the function <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.randomSplit\">`randomSplit`</a>.\n",
    "\n",
    "> Count the number of examples, and subjects in class '+1' in each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of examples in the dataset :  351\n",
      "The number of examples in the training dataset :  335\n",
      "The number of examples in the testing dataset :  16\n",
      "\n",
      "The number of examples in class +1 dataset :  225\n",
      "The number of examples in class +1 training dataset :  218\n",
      "The number of examples in class +1 testing dataset:  7\n"
     ]
    }
   ],
   "source": [
    "trainingData, testingData = scaledNormData.randomSplit([95, 5])\n",
    "print(\"The number of examples in the dataset : \",nbExamples(scaledNormData))\n",
    "print(\"The number of examples in the training dataset : \",nbExamples(trainingData))\n",
    "print(\"The number of examples in the testing dataset : \",nbExamples(testingData))\n",
    "\n",
    "classPlus1Data = scaledNormData.filter(lambda line : line.label == 1)\n",
    "classPlus1TrainingData = trainingData.filter(lambda line : line.label == 1)\n",
    "classPlus1TestingData = testingData.filter(lambda line : line.label == 1)\n",
    "print(\"\\nThe number of examples in class +1 dataset : \",nbExamples(classPlus1Data))\n",
    "print(\"The number of examples in class +1 training dataset : \",nbExamples(classPlus1TrainingData))\n",
    "print(\"The number of examples in class +1 testing dataset: \",nbExamples(classPlus1TestingData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Minimization of the logistic loss with the Gradient algorithm\n",
    "\n",
    "The goal of this section is to: \n",
    "1. Compute gradients of the loss functions.\n",
    "2. Implement a Gradient algorithm.\n",
    "3. Observe the prediction accuracy of the developed methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 4__\n",
    ">Define a routine computing functional loss and gradient from one example \n",
    "\n",
    "For a Labeled point <tt>example</tt> (`LabeledPoint(example.label,example.features)`) that we denoted $(b_i,a_i)$ and a regressor <tt>x</tt>, compute $f_i(x) = \\log(1+\\exp(-b_i \\langle a_i,x\\rangle) )$ and $\\nabla f_i(x)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The logistic loss for the first example is :\n",
      " 0.18863205254056248\n"
     ]
    }
   ],
   "source": [
    "from math import *\n",
    "from random import *\n",
    "\n",
    "import numpy as np\n",
    "def logistic_loss_per_example(example,x):\n",
    "    \"\"\" Computes the logistic loss for a Labeled point\n",
    "    Args:\n",
    "        example: a labeled point\n",
    "        x: regressor\n",
    "    Returns:\n",
    "        real value: l \n",
    "    \"\"\"\n",
    "    f = log(1 + exp(-1 * example.label * np.dot(example.features,x)))\n",
    "\n",
    "    return f\n",
    "\n",
    "def randomArray(size) :\n",
    "    x = np.zeros(size)\n",
    "    for i in range(1,size) :\n",
    "        x[i] = uniform(0,1)\n",
    "    return x\n",
    "\n",
    "size = trainingData.first().features.size\n",
    "testLoss = trainingData.map(lambda line : logistic_loss_per_example(line,randomArray(size)))\n",
    "print(\"The logistic loss for the first example is :\\n\",testLoss.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The logistic grad for the first example is :\n",
      " [-0.0535393523216,-0.0,-0.0532925359074,0.00315293245822,-0.0456385500995,-0.00123461746454,-0.0446507490492,0.0201886189734,-0.0535393523216,-0.00201307964729,-0.0456385500995,0.0095059120047,-0.0319924399798,0.0240632619009,-0.0324105823214,0.0204643466379,-0.0451636560444,0.0206351371718,-0.0311663277734,0.0172353882994,-0.0305019044111,0.0158872674079,-0.0197806491087,0.0253546310789,-0.0304162414474,0.0273966219765,-0.0219928951467,0.0247180481798,-0.0113856786647,0.0182515652064,-0.0226294780458,0.0291719868995,-0.00998027066627,0.0242533266017,-0.171908855321]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def logistic_grad_per_example(example,x):\n",
    "    \"\"\" Computes the logistic gradient for a Labeled point\n",
    "    Args:\n",
    "        example: a labeled point\n",
    "        x: regressor\n",
    "    Returns:\n",
    "        numpy array: g \n",
    "    \"\"\"\n",
    "    g = (-1 * example.label * example.features)/(1 + exp(example.label * np.dot(example.features,x)))\n",
    "    return  g\n",
    "\n",
    "testGradientLoss = trainingData.map(lambda line : logistic_grad_per_example(line,randomArray(size)))\n",
    "print(\"The logistic grad for the first example is :\\n\",testGradientLoss.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 5__\n",
    ">Implement a gradient descent algorithm to minimize\n",
    "\\begin{align*}\n",
    "\\min_{x\\in\\mathbb{R}^d } f(x) := \\frac{1}{m}  \\sum_{i=1}^m  \\log( 1+\\exp(-b_i \\langle a_i,x \\rangle) ) = \\frac{1}{m}  \\sum_{i=1}^m f_i(x).\n",
    "\\end{align*}\n",
    ">by \n",
    "* defining a function taking a stepsize and a maximal number of iterations and returning the final point as well as the value of $f(x)$ at each iteration. \n",
    "* running `x, f_tab = grad_algo(gamma,MAX_ITE)`\n",
    "\n",
    "\n",
    "For the choice of the stepsize, we help you by provinding you an upper bound on the Lipschitz constant $L$ of $\\nabla f$:\n",
    "\n",
    "$ L \\leq L_b = \\max_i 0.25 \\|a_i\\|_2^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_gamma1():\n",
    "    Lb = 0.25 * trainingData.map(lambda line : pow(np.linalg.norm(line.features,2),2)).max()\n",
    "    return 1/Lb\n",
    "print(\"Limite :\",compute_gamma1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grad_algo(gamma, MAX_ITER):\n",
    "    i = 0\n",
    "    x = randomArray(size)\n",
    "    m = trainingData.count()\n",
    "    f_tab = np.zeros(MAX_ITER)\n",
    "    while i < MAX_ITER:\n",
    "        print(i, end=' ')\n",
    "        f = trainingData.map(lambda line : (1/m) * logistic_grad_per_example(line,x)).sum()\n",
    "        f_tab[i] = trainingData.map(lambda line : (1/m) * logistic_loss_per_example(line,x)).sum()\n",
    "        x = x - gamma * f    \n",
    "        i += 1\n",
    "    return x, f_tab\n",
    "\n",
    "MAX_ITER = 20\n",
    "x, f_tab = grad_algo(compute_gamma1(),MAX_ITER)\n",
    "print(\"\\nx =\",x,\"\\nf_tab =\",f_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 6__\n",
    "\n",
    "> Plot the functional value versus the iterations.\n",
    "\n",
    "> Investigate if the computations are distributed over different threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAF5CAYAAABeAGpJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyPTUMBAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe30dcefe48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "MAX_ITER = 100\n",
    "plt.figure()\n",
    "plt.plot(range(MAX_ITER), f_tab, color=\"red\", linewidth=1.0, linestyle=\"-\")\n",
    "plt.xlim(0, MAX_ITER)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Functional value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized logisitic regression\n",
    "\n",
    "In addition to the loss, it is usual to add a regularization term of the form\n",
    "$$ r(x) = \\lambda_1 \\|x\\|_1 + \\lambda_2 \\|x\\|^2_2 $$\n",
    "\n",
    "The first part promotes sparsity of the iterates while the second part prevents over-fitting. \n",
    "This kind of regularization is often called:\n",
    "- *elastic-net* when $ \\lambda_1$ and $ \\lambda_2$ are non-null\n",
    "- $\\ell_1$ when $\\lambda_2 = 0$\n",
    "- *Tikhonov* when $\\lambda_1 = 0$\n",
    "\n",
    "The full optimization problems now writes\n",
    "\\begin{align*}\n",
    "\\min_{x\\in\\mathbb{R}^d } g(x) =  \\frac{1}{m}  \\sum_{i=1}^m  \\log( 1+\\exp(-b_i \\langle a_i,x \\rangle) ) +  \\lambda_1 \\|x\\|_1 + \\lambda_2 \\|x\\|^2_2\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "__Question 7__\n",
    "\n",
    "> Which part of $g$ is smooth, which part is not? Write $g$ as \n",
    "$$ g(x) =  \\frac{1}{m}  \\sum_{i=1}^m s_i(x) + n(x)  $$\n",
    "where the $(s_i)$ are smooth function and $n$ is non smooth.\n",
    "\n",
    "> ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    ">      --> \\lambda_1 \\|x\\|_1 is not differentiable at 0 --> not smooth function\n",
    "\n",
    ">      The reasons for regularization are \n",
    "\n",
    ">       1) to avoid overfitting by not generating high coefficients for predictors that are sparse.  \n",
    "\n",
    ">       2) to stabilize the estimates especially when there's collinearity in the data.  \n",
    "\n",
    "> ----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "> Define a function `regularized_logistic_grad_per_example(examples,x)` returning the gradient of the smooth part per example (i.e. $\\nabla s_i(x)$)\n",
    "\n",
    "> Define a function `n_prox(x,gamma)` returning the proximal operator of the non-smooth part (i.e. $\\mathbf{prox}_{\\gamma n}(y)$)\n",
    "\n",
    "we recall that\n",
    "$$ \\mathbf{prox}_{\\gamma n}(y) = \\arg\\min_x\\left\\{ n(x) + \\frac{1}{2\\gamma} \\|x-y\\|_2^2 \\right\\} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Part I\n",
    "m = trainingData.count()\n",
    "def regularized_logistic_grad_per_example(examples,x,lambda2):\n",
    "    return logistic_grad_per_example(examples,x) + 2 * lambda2 * x \n",
    "\n",
    "testRegularizedGradientLoss = trainingData.map(lambda line : regularized_logistic_grad_per_example(line,randomArray(size),0.5))\n",
    "print(\"The regularized logistic grad for the first example is :\\n\",testRegularizedGradientLoss.first(),\"\\n\")\n",
    "\n",
    "# Part II\n",
    "def n_prox(x,gamma):\n",
    "    res = np.zeros(size)\n",
    "    for i in range(1,size):\n",
    "        if x[i] > gamma :\n",
    "            res[i] = x[i] - gamma\n",
    "        elif x[i] < -gamma :\n",
    "            res[i] = x[i] + gamma\n",
    "        else :\n",
    "            res[i] = 0\n",
    "    return res\n",
    "print(\"The proximal operator of the non-smooth part is :\\n\",n_prox(randomArray(size),0.6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 8__\n",
    "\n",
    "> Compute a proximal gradient algorithm for computing a solution of\n",
    "$$ \\min_x  f(x) + r(x) = \\frac{1}{m}  \\sum_{i=1}^m  \\log( 1+\\exp(-b_i \\langle a_i,x \\rangle) ) + \\lambda_1 \\|x\\|_1 + \\lambda_2 \\|x\\|^2_2 $$\n",
    "\n",
    "\n",
    "Hint: An admissible stepsize can be found by taking $\\gamma = 1/L_{b2}$ with  $ L_b = \\max_i 0.25 \\|a_i\\|_2^2 + 2\\lambda_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Part I\n",
    "MAX_ITER = 20\n",
    "def compute_gamma2(lambda2):\n",
    "    Lb = 0.25 * trainingData.map(lambda line : pow(np.linalg.norm(line.features,2),2)).max() \\\n",
    "        + lambda2 * 2 \n",
    "    return 1/Lb\n",
    "print(\"Gamma value :\",compute_gamma2(0.5),\"\\n\")\n",
    "\n",
    "# Part II\n",
    "def prox_grad_algo(lambda1,lambda2):\n",
    "    i = 0\n",
    "    gamma = compute_gamma2(lambda2)\n",
    "    x = randomArray(size)\n",
    "    g_tab = np.zeros(MAX_ITER)\n",
    "    while i < MAX_ITER:\n",
    "        print(i, end=' ')\n",
    "        g = trainingData.map(lambda line : (1/m) * regularized_logistic_grad_per_example(line,x,lambda2)).sum()\n",
    "        g_tab[i] = trainingData.map(lambda line : (1/m) * logistic_loss_per_example(line,x)).sum() + \\\n",
    "                                    lambda1 * np.linalg.norm(x,1) + lambda2 * pow(np.linalg.norm(x,2),2)\n",
    "        x = n_prox(x - gamma * g,lambda1*gamma) \n",
    "        i += 1\n",
    "    return x, g_tab\n",
    "\n",
    "#x, g_tab = prox_grad_algo(0,0)\n",
    "#print(\"\\nx =\",x,\"\\nf_tab =\",g_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 9__\n",
    "\n",
    "> Examine the behavior and output of your proximal gradient algorithm with different values of $\\lambda_1$, $\\lambda_2$. What do you observe in terms of sparsity of the solution and convergence rate of the algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def compute_min(l1,l2):\n",
    "    x, g_tab = prox_grad_algo(l1,l2)\n",
    "    return x, g_tab\n",
    "\n",
    "lamb1 = [0,1,0,1]\n",
    "lamb2 = [0,0,1,1]\n",
    "x     = [0,0,0,0]\n",
    "g_tab = [0,0,0,0]\n",
    "for i in range(0,1):\n",
    "    x[i], g_tab[i] = compute_min(lamb1[i],lamb2[i])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Courbe 1 [ red ]\n",
      "lambda1 = 0 \n",
      "lambda2 = 0 \n",
      "gamma = 1.9999999999999991\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAF5CAYAAABEPIrHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe306ef7550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_res(x,g_tab,col):\n",
    "    plt.plot(range(MAX_ITER-2), g_tab[2:], col, linewidth=1.0, linestyle=\"-\")\n",
    "    \n",
    "colors = [\"red\", \"green\", \"blue\",\"black\"]\n",
    "plt.figure()\n",
    "for i in range(0,1):\n",
    "    print(\"\\nCourbe\", i+1, \"[\",colors[i],\"]\\nlambda1 =\", lamb1[i], \"\\nlambda2 =\",\\\n",
    "        lamb2[i], \"\\ngamma =\", compute_gamma2(lamb2[i]))\n",
    "    plot_res(x[i],g_tab[i],colors[i])\n",
    "plt.xlim(0, MAX_ITER)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Functional value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Question 10__\n",
    "\n",
    "> Write a function that evaluates the accuracy of the classification on the training dataset.\n",
    "\n",
    "> Investigate how this accuracy change when playing with the regularization terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_label :\n",
      " [1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "test : 0 \n",
      " [0.0, 0.0, 0.0, 2.0, 0.0, 0.0, -2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, -2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, -2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] \n",
      " x = \n",
      " [ 0.53510937  0.08602598  1.53474985  0.81863734  1.07387433  1.16288068\n",
      "  0.89573337  0.89957343  0.51614423  0.33836166  0.26579581  1.17297032\n",
      "  0.31781913  0.89646177  0.6239572   0.9308935   0.09830154  0.1629787\n",
      "  0.11966527 -0.0564775   0.87293106 -0.12479582  0.33701162  0.62089987\n",
      "  0.2612231   0.46003373 -0.39694385  0.18844469  0.8426073   0.44454568\n",
      "  0.42269245  0.4933965   1.11356829  0.45476997 -0.70186373] \n",
      "\n",
      "test : 1 \n",
      " [0.0, 0.0, 0.0, 2.0, 0.0, 0.0, -2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, -2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] \n",
      " x = \n",
      " [ 0.50202024  0.93703872  1.41802397  0.42885395  1.16748587  0.82685152\n",
      "  0.90066436  1.27469669  0.45421708  0.56514136  0.27540792  1.0391297\n",
      "  0.30701746  0.50281287  0.06249168  0.6286709   0.63266796  0.89084797\n",
      "  0.02025652 -0.00585472  0.46377365  0.07626805  0.53944599  0.00699227\n",
      "  0.69027146 -0.13951336  0.07449812  0.15778987  1.10861766  0.76310105\n",
      "  0.68033957 -0.16085143  0.72007935  0.42663437 -0.81217024] \n",
      "\n",
      "test : 2 \n",
      " [0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] \n",
      " x = \n",
      " [  2.97703531e-02   7.76652480e-15   3.00195070e-02   3.93072212e-03\n",
      "   3.01732068e-02   6.72199079e-03   2.59128704e-02   1.00663310e-02\n",
      "   1.91558426e-02   7.29902701e-03   1.52578572e-02   9.22472467e-03\n",
      "   1.54234992e-02   7.69527456e-03   1.54940694e-02   5.84409888e-03\n",
      "   1.06205624e-02   2.71709852e-03   1.18828326e-02   1.42828801e-03\n",
      "   1.56527813e-02  -4.30636073e-03   1.52672574e-02  -1.57455505e-03\n",
      "   1.50053541e-02  -2.14778429e-03   6.51906194e-03   6.46469631e-04\n",
      "   1.70742369e-02   3.86233723e-04   1.71486556e-02  -8.66273955e-04\n",
      "   1.58136139e-02  -1.53288942e-03   5.95047855e-02] \n",
      "\n",
      "test : 3 \n",
      " [0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] \n",
      " x = \n",
      " [  2.97703531e-02   3.06919749e-15   3.00195070e-02   3.93072212e-03\n",
      "   3.01732068e-02   6.72199079e-03   2.59128704e-02   1.00663310e-02\n",
      "   1.91558426e-02   7.29902701e-03   1.52578572e-02   9.22472467e-03\n",
      "   1.54234992e-02   7.69527456e-03   1.54940694e-02   5.84409888e-03\n",
      "   1.06205624e-02   2.71709852e-03   1.18828326e-02   1.42828801e-03\n",
      "   1.56527813e-02  -4.30636073e-03   1.52672574e-02  -1.57455505e-03\n",
      "   1.50053541e-02  -2.14778429e-03   6.51906194e-03   6.46469631e-04\n",
      "   1.70742369e-02   3.86233724e-04   1.71486556e-02  -8.66273955e-04\n",
      "   1.58136139e-02  -1.53288942e-03   5.95047855e-02] \n",
      "\n",
      "erreur pour x[ 0 ] = 0.1712538226299694 \n",
      "\n",
      "erreur pour x[ 1 ] = 0.1559633027522936 \n",
      "\n",
      "erreur pour x[ 2 ] = 0.3547400611620795 \n",
      "\n",
      "erreur pour x[ 3 ] = 0.3547400611620795 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 1\n",
    "training_size = trainingData.count()\n",
    "def diff_tableau(a,b):\n",
    "    s = a\n",
    "    for i in range(0,training_size):\n",
    "        s[i] = a[i] - b[i]\n",
    "    return s\n",
    "\n",
    "#Labelisation\n",
    "def p(x,example):\n",
    "      #  label = 0\n",
    "    p = 1/(1+exp(-1 * np.dot(example.features,x)))\n",
    "    if p > 0.5:\n",
    "        label = 1.0\n",
    "    else:\n",
    "        label = -1.0\n",
    "    return label\n",
    "\n",
    "# test\n",
    "train = trainingData\n",
    "def test_train(train,x):\n",
    "    return train.map(lambda line : p(x,line))\n",
    "\n",
    "diff = [0,0,0,0]\n",
    "true_label = train.map(lambda line: line.label)\n",
    "print(\"true_label :\\n\",true_label.collect())\n",
    "for i in range(0,4):\n",
    "    test = test_train(train,x[i])\n",
    "    diff[i] = diff_tableau(test.collect(),true_label.collect())\n",
    "    print(\"test :\",i,\"\\n\",diff_tableau(test.collect(),true_label.collect()),\"\\n x = \\n\",x[i],\"\\n\")\n",
    "\n",
    "# Part 2\n",
    "def pourcentage_erreur(diff):\n",
    "    return sum([abs(_i) for _i in diff]) /(2*training_size)\n",
    "\n",
    "erreur = [0,0,0,0]\n",
    "for i in range(0,4):\n",
    "    erreur[i] = pourcentage_erreur(diff[i])\n",
    "    print(\"erreur pour x[\",i,\"] =\",erreur[i],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To go further\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accelerations\n",
    "\n",
    "A popular acceleration method to improve the convergence rate of proximal gradient algorithm is the addition of inertia. That is, contructing the next gradient input by a combination of the last two outputs.\n",
    "\n",
    "\n",
    "In particular, Nesterov's acceleration is the most popular form of inertia. It writes\n",
    "$$ \\left\\{ \\begin{array}{l}   y_{k+1} = \\mathbf{prox\\_grad}(x_k) \\\\ x_{k+1} = y_{k+1} + \\alpha_{k+1} (y_{k+1} - y_k)  \\end{array} \\right. $$ \n",
    "with\n",
    "* $\\mathbf{prox\\_grad}$ the proximal gradient operation\n",
    "* $(\\alpha_{k})$ the inertial sequence defined as $\\alpha_k = \\frac{t_k-1}{t_{k+1}}$ and $t_0 = 0$ and $t_{k+1} = \\frac{1+\\sqrt{1+4t_k^2}}{2}$\n",
    "\n",
    "__Question 11__\n",
    "\n",
    "> Implement a fast proximal gradient with this kind of inertia (This algorithm is often nicknamed FISTA).\n",
    "\n",
    "> Compare the convergence speed with the vanilla proximal gradient algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 \n",
      "x = [-0.0929440408261,0.0,-0.0838210332828,-0.00926598996178,-0.083186733799,-0.0169225195089,-0.0727228170314,-0.0236599844043,-0.058119000405,-0.0198553632333,-0.0492245227492,-0.0227434489334,-0.0472883852994,-0.018312724868,-0.0461721916766,-0.0137815671576,-0.037213096962,-0.00537403796808,-0.0389572344975,-0.00170590954338,-0.0458296852216,0.0083395565557,-0.0456913817464,0.00480727043163,-0.0456190586598,0.00634672413928,-0.032276711508,0.00058489121323,-0.0492293272949,-7.57495173294e-05,-0.0490803780457,0.00218731323647,-0.0457876285274,0.00267720143475,-0.23758940736] \n",
      "h_tab = [ 0.16664556  0.18561123  0.31459995  0.34915818  0.34762094  0.34079363\n",
      "  0.33739856  0.33696969  0.33749519  0.33789803  0.33800329  0.33796368\n",
      "  0.33791317  0.33789348  0.33789515  0.33790148  0.33790486  0.33790516\n",
      "  0.3379044   0.33790385  0.33790373  0.33790381  0.3379039   0.33790393\n",
      "  0.33790392  0.33790391  0.3379039   0.3379039   0.3379039   0.3379039\n",
      "  0.3379039   0.3379039   0.3379039   0.3379039   0.3379039   0.3379039\n",
      "  0.3379039   0.3379039   0.3379039   0.3379039   0.3379039   0.3379039\n",
      "  0.3379039   0.3379039   0.3379039   0.3379039   0.3379039   0.3379039\n",
      "  0.3379039   0.3379039   0.3379039   0.3379039   0.3379039   0.3379039\n",
      "  0.3379039   0.3379039   0.3379039   0.3379039   0.3379039   0.3379039\n",
      "  0.3379039   0.3379039   0.3379039   0.3379039   0.3379039   0.3379039\n",
      "  0.3379039   0.3379039   0.3379039   0.3379039   0.3379039   0.3379039\n",
      "  0.3379039   0.3379039   0.3379039   0.3379039   0.3379039   0.3379039\n",
      "  0.3379039   0.3379039   0.3379039   0.3379039   0.3379039   0.3379039\n",
      "  0.3379039   0.3379039   0.3379039   0.3379039   0.3379039   0.3379039\n",
      "  0.3379039   0.3379039   0.3379039   0.3379039   0.3379039   0.3379039\n",
      "  0.3379039   0.3379039   0.3379039   0.3379039 ]\n"
     ]
    }
   ],
   "source": [
    "def FISTA_prox_grad_algo(lambda1,lambda2):\n",
    "    \n",
    "    t_kPlus1 = 1\n",
    "    \n",
    "    y_k = randomArray(size)\n",
    "    y_kPlus1 = randomArray(size)\n",
    "        \n",
    "    x = randomArray(size)\n",
    "\n",
    "    i = 0\n",
    "    h_tab = np.zeros(MAX_ITER)\n",
    "    gamma = compute_gamma2(lambda2)\n",
    "    \n",
    "    while i < MAX_ITER:\n",
    "        print(i, end =' ')\n",
    "        y_kPlus1 = trainingData.map(lambda line : (1/m) * regularized_logistic_grad_per_example(line,x,lambda2)).sum() \\\n",
    "                            + n_prox(lambda1 * x,gamma)\n",
    "        h_tab[i] = y_kPlus1.norm(2)\n",
    "        t_kPlus2 = (1 + sqrt(1 + 4 * t_kPlus1 * t_kPlus1)) / 2\n",
    "        alpha_kPlus1 = (t_kPlus1 - 1) / t_kPlus2\n",
    "        x = y_kPlus1 + alpha_kPlus1 * (y_kPlus1 - y_k)\n",
    "        \n",
    "        i += 1\n",
    "        y_k = y_kPlus1\n",
    "        t_kPlus1 = t_kPlus2\n",
    "    return x, h_tab\n",
    "MAX_ITER = 100\n",
    "x, h_tab = FISTA_prox_grad_algo(0,0)\n",
    "print(\"\\nx =\",x,\"\\nh_tab =\",h_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAF5CAYAAABEPIrHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe30d2d5198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"red\", \"green\", \"blue\",\"black\"]\n",
    "plt.figure()\n",
    "#for i in range(0,4):\n",
    "#    print(\"\\nCourbe\", i+1, \"[\",colors[i],\"]\\nlambda1 =\", lamb1[i], \"\\nlambda2 =\",\\\n",
    "#        lamb2[i], \"\\ngamma =\", compute_gamma2(lamb2[i]))\n",
    "#    plot_res(x[i],g_tab[i],colors[i])\n",
    "plt.plot(range(MAX_ITER), h_tab, color=\"yellow\", linewidth=1.0, linestyle=\"-\")\n",
    "plt.xlim(0, MAX_ITER)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Functional value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental methods\n",
    "\n",
    "When dimension increases, incremental algorithms are often priviledged. \n",
    "\n",
    "A possible incremental algorithm for a problem such as regularized logistic regression is MISO (see *J Mairal. Incremental Majorization-Minimization Optimization with Application to Large-Scale Machine Learning. SIAM Journal on Optimization,2015 and ICML 2014.*):\n",
    "\n",
    "* Draw randomly a sample $n$\n",
    "* Compute $x^n_{k+1} = \\mathbf{prox}_{\\gamma g} (\\bar{x}_k) - \\gamma \\nabla f_n(\\mathbf{prox}_{\\gamma g} (\\bar{x}_k) )$\n",
    "* For all $i\\neq n$, $x^i_{k+1}=x^i_k$ \n",
    "* Compute new $\\bar{x}_{k+1} = \\frac{1}{m} \\sum_{j=1}^m x^j_{k+1}$\n",
    " \n",
    "\n",
    "__Question 12__\n",
    "\n",
    "> Implement this incremental algorithm and compare with the previous algorithms in terms of convergence time and functional value versus number of passes over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
